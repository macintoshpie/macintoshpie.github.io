- Ted Summer
  - => /images/me-circle.png
  - things I like 🍓
    - music
      - => https://www.youtube.com/embed/liS_be9MK00
      - I have a microkorg and make music in Ableton. Amateur pianist.
        - => /images/cruella.png
      - => https://www.youtube.com/embed/4An4oR035j8
    - climbing
    - biking
      - I'm into 90s mountain bikes right now. I have a '93 raleigh m-40 currently
      - => /images/my-raleigh.png
    - hyperlinks
      - => https://100r.co/
      - => http://www.musanim.com/all/
      - => https://mollysoda.exposed/
      - => http://www.beerxml.com/
    - css
      - just kidding i have no idea how to use it properly


- sometimes I make things
  - this website (lists version)
    - This website is written as a single file as a big list
      - roughly follows syntax follows gemini gemfile format. will probably move further away from it as I go because its mine
  - tombola: generative music
    - Inspired by Teenage Engineering OP-1's tombola sequencer.
    - => https://tombola.tedsummer.com/
    - => /images/tombola.png
  - liztz: notes as lists
    - A lightweight note taking application centered around lists.
    - => /images/liztz.png
  - tasks: timeline estimation
    - A timeline estimator for multiple tasks. Uses Monte Carlo simulations to estimate when a collection of tasks will be complete. Mostly an exercise in creating fluid UI/UX.
    - => /images/tasks.png
    - => https://en.wikipedia.org/wiki/Monte_Carlo_method#An_example
  - => https://actionsbyexample.com
    - GitHub Actions by Example is an introduction to GitHub’s Actions and Workflows through annotated example YAML files. I wrote a custom HTML generator in Golang to generate the documentation from YAML files.
    - => /images/actionsbyexample.png
  - mixtapexyz
    - A game where players build themed music playlists with friends. Had some fun writing a custom router in Golang.
    - => https://www.mxtp.xyz/
    - => /images/mxtp.png
  - convoh
    - chat with yourself
    - => https://convoh.netlify.app
    - => /images/convoh.png
  - freedb.me
    - free sqlite databases. queried through HTTP API. hand made with go
    - https://freedb.me
    - => /images/freedb.png
  - jot
    - Post-it notes and scheduled reminders app.
    - https://jot.tedsummer.com
    - => /images/jot.png
  - paropt: tool optimization automation
    - => https://github.com/macintoshpie/paropt
    - => /images/paropt.png
    - => https://ieeexplore.ieee.org/abstract/document/8968866
  - pixel synth
    - Pixel-based video synthesizer in HTML/JS
    - => /images/pixsynth.png
  - maze solving twitter bot
    - Twitter bot which solves another Twitter bot’s ASCII mazes. Looks like it's banned now. thanks elon ®
    - => /images/minimazesolver.png
  - pentaku js
    - Play against a friend or naive bots in pentago, gomoku, and other grid based games.
    - => /images/pentaku.png


- sometimes I write
  - $ shorts
    - perl should have used the keyword "my" for constants and "our" for variables
      - ```
my $NAME = "ted";
our @shared_friends = ("alice", "bob", "charlie");
```
      - it also should have used camel case
  - $ linoleum
    - I wanted to make some prints on hats for a "running party" we were having. A mouse dubbed [Mr. Jiggy](https://banjokazooie.fandom.com/wiki/Jiggy) lives (lived) with us, so I wanted him as a mascot on each teams hat. So I bought some linoleum, cheap ass tools, and speedball fabric ink off amazon.
    - I found a chinese site that sells hat blanks, but I would not recommend it because the hats I received did not look like the advertised product. 1 star.
    - => /images/jiggy.JPG
    - > mr. jiggy lived in our dishwasher and while playing banjo kazooie after my roommate had a heatstroke we though it was really funny to name him that (her? we don't know).
    - I asked Dall-E to generate some photos of linoleum mice as a starting place then handdrew a simplified version onto the linoleum.
    - This worked out pretty well other than the fact that I probably made it slightly too small (~2x2 inches) and it was really hard to get the hair detail. Not much to say about the cutting. 
    - => /images/jiggy-print.png
    - I of course forgot that the print would be "in reverse" (flipped on horizontally) but who cares when it's a mouse. It would have been a problem if I stuck with the original plan of writing "stay sweaty" in Bosnian underneath but I scrapped that after our Bosnian friend began to explain the fact that Bosnian has gendered nouns and I didn't like the longer alternatives.
    - Though I just did some googling/llming and found some cool bosnian bro speak like "živa legenda" (living legend) which would have been dope.

    - => /images/amjo-brate-shirt.png
    - > chatgpt tells me "ajmo brate" says "lets go bro" and I found this shirt on amazon (supposedly) saying "let's go bro, sit in the tavern, order, drink, and eat, let the eyes shine from the wine, we don't live for a thousand years" which is a sentiment I appreciate

    - I rolled the ink on 4th of july paper plates that were too small. I will be looking for glass panes or something similar for rolling ink at the animal crossing store in future visits.
    - I learned that I have no idea how much ink to use, and that you should put a solid thing behind whatever you're printing on (the mesh backing left a pattern in the first print). But it does seem cool to experiment printing with some patterned texture behind the print.
    - I had been warned that nylon is a terrible fabric to print on but I did it anyways.
    - It's still not fully dry after 12 hours but whatever. we'll see. it'll probably wash out.

    - The first few hats looked ok. In future prints I'd like to try a few things:
      - simpler design
      - bigger design (~2.5 inches)
      - trim off more of the excess linoleum when working with awkward printing surfaces

    - => /images/jiggy-hats.png
    - > the white print had way too much ink I think. The black print looks wonky because I printed without a solid surface behind the fabric (the mesh behind the hat came through).
  - $ aws lambda: local server
    - I've been messing around with a project which uses netlify and lambda (it's free and static sites are hawt). I basically have one main lambda function which handles api requests built in golang. It's pretty awesome how easy netlify lets you build and deploy, but I wanted to a nice local setup for building and testing my api server. I think aws has its own tooling for this, but I didn't really want to start fooling with it, so I came up with this.
    - First, use a docker container docker-lambda to actually "run" the lambda. This is an awesome container, but you have to use the lambda API for interacting with the service. That's no good because our frontend shouldn't care about the lambda API, and it should just use the API gateway netlify uses for the functions.
      - => https://github.com/lambci/docker-lambda
    - To fix this, I created a small python proxy takes requests, converts them into API Gateway requests, forwards it to our docker container with the lambda, then converts the API Gateway response into a normal HTTP response. I _really_ struggled to get the python request handler to do all of the things I wanted, but eventually I got it working.
    - Here's the full script I use to run the lambda as an HTTP API locally. Since I'm using golang I use the `go1.x` tag for the container and provide the path to the executable. Also, I ended up wrapping the python starting process in a loop b/c it was taking a while for the port to become available again after killing and restarting the script.
      - ```bash
#! /bin/bash
# Starts a a mock lambda server allowing you to make requests
set -e

# build my go executable
make build

docker rm -f lambda_service 2>&1 >/dev/null || true
docker run -d --rm \
    --name lambda_service \
    -p 9001:9001 \
    -e DOCKER_LAMBDA_STAY_OPEN=1 \
    --env-file .env \
    -v "$PWD":/var/task:ro,delegated \
    # Change tag and path to executable as needed
    lambci/lambda:go1.x ./bin/functions/jockey

# start a proxy server that handles translating to and from APIGateway request/responses
python3 -c '
from http.server import BaseHTTPRequestHandler
from http.client import parse_headers
import socketserver
from urllib.request import urlopen
from json import dumps, loads
import os
import time

PORT = 8000
LAMBDA_PORT = int(os.getenv("LAMBDA_PORT", "9001"))

class Proxy(BaseHTTPRequestHandler):
    # change the function name as needed (my functions name is jockey)
    lambda_endpoint = f"http://localhost:{LAMBDA_PORT}/2015-03-31/functions/jockey/invocations"
    def proxy_it(self):
        content_length = self.headers["Content-Length"]
        data_string = ""
        if content_length:
            data_string = self.rfile.read(int(content_length)).decode()
        constructed_request = {
            "path": self.path,
            "httpMethod": self.command,
            "body": data_string,
            "headers": {k: self.headers[k] for k in self.headers.keys()}
        }
        print("Sending Request: ", constructed_request)
        response = urlopen(self.lambda_endpoint, dumps(constructed_request).encode())

        body = response.read().decode()
        http_response = loads(body)
        print("\nGot Response: ", http_response)

        headers = http_response.get("headers", {})
        body = http_response["body"] if http_response.get("body") else ""
        status_code = http_response.get("statusCode", 500)
        self.send_response(status_code)
        for header, value in headers.items():
            self.send_header(header, value)
        self.end_headers()
        self.wfile.write(bytes(body, "utf-8"))

    def do_GET(self):
        self.proxy_it()

    def do_POST(self):
        self.proxy_it()

    def do_OPTIONS(self):
        self.proxy_it()

started = False
while not started:
    try:
        with socketserver.TCPServer(("", PORT), Proxy) as httpd:
            started = True
            print(f"Proxying from port {PORT} to {LAMBDA_PORT}")
            httpd.serve_forever()
    except:
        print("Port still occupied, waiting...")
        time.sleep(5)
'
```
    - This could probably be improved but it's worked so far for my toy project. One significant improvement to this process would be to have the docker container auto rebuild the function whenever it changes, but I've yet to add that.
  - $ jq: looping
    - Here's a quick example of using jq in a for loop. jq has some nice functional stuff built in such as `map()`, but sometimes you need to do some fancy stuff with the data. This might be useful when you've filtered a jq array, and then need to iterate over the objects to do some work that you can't do in jq alone.
    - For this example, the goal is to iterate through an array of user objects, downloading their pictures. We'll use some fake user data from https://reqres.in/, you can download it with the script below
      - script
        - ```bash
curl https://reqres.in/api/users?page=1 > user_loop.json
```
      - output
        - ```JSON
{
  "page": 1,
  "per_page": 6,
  "total": 12,
  "total_pages": 2,
  "data": [
    {
      "id": 1,
      "email": "george.bluth@reqres.in",
      "first_name": "George",
      "last_name": "Bluth",
      "avatar": "https://s3.amazonaws.com/uifaces/faces/twitter/calebogden/128.jpg"
    },
    {
      "id": 2,
      "email": "janet.weaver@reqres.in",
      "first_name": "Janet",
      "last_name": "Weaver",
      "avatar": "https://s3.amazonaws.com/uifaces/faces/twitter/josephstein/128.jpg"
    },
    ...
  ]
}
```
    - The finished result
      - ```bash
imagesDir="tmp_user_images"
mkdir -p $imagesDir

while read -r user; do
  avatarURL=$(echo $user | jq -r '.avatar')
  imagePath="${imagesDir}/$(echo $user | jq -r '.first_name + .last_name').jpg"
  echo "Downloading ${avatarURL} to ${imagePath}"
  curl -s -o ${imagePath} ${avatarURL}
done <<< "$(cat user_loop.json | jq -c '.data[]')"
```
    - The part of interest (the looping), is written like this
      - ```bash
while read -r user; do
  # do work on user object
done <<< "$(cat user_loop.json | jq -c '.data[]')"
```
    - ## Breakdown
      - ### Get the objects
        - First, we care only about the `data` array which stores our user objects containing the URLs, so we use that object id to access it:
        - ```bash
cat user_loop.json | jq -c '.data[]'
```
        - Notice `-c` flag, it's important for looping over the objects. This tells jq to put each object onto a single line, which we'll use in the loop.

      - ### Loop over lines
        - In bash, we can loop over lines by using the `while read -r varName; do ...; done <<< "$lineSeparatedVar"` pattern. `read -r <name>` will read in a line from STDIN, then assign the value to `<name>`; the `-r` flag tells `read` "do not allow backslashes to escape any characters".  
        - Now we can loop over objects from our array like so
        - ```bash
while read -r user; do
  # do work on user object
done <<< "$(cat user_loop.json | jq -c '.data[]')"
```
    - ## Notes
      - I've not fully tested this code. You may want to base64 encode the objects, then decode them if you wanna be really safe.
      - `curl` concurrently, toss a `&` on the end of the curl to run it as a background process

  - jq: group, unique, average
    - Recently I've been running through picoCTF 2018 and saw this problem that can be solved with some cool stuff from jq (a handy JSON processor for the command line).
    - => https://2018game.picoctf.com/
    - => https://stedolan.github.io/jq/
    - Question: What is the number of unique destination IPs a file is sent to, on average?  
      - A shortened version of the provided data, `incidents.json`, is below.
        - ```JSON
{
  "tickets": [
    {
      "ticket_id": 0,
      "timestamp": "2017/06/10 07:50:14",
      "file_hash": "fb0abe9b2a37e234",
      "src_ip": "131.90.8.180",
      "dst_ip": "104.97.128.21"
    },
    {
      "ticket_id": 1,
      "timestamp": "2017/06/11 05:19:56",
      "file_hash": "f2d8740404ff1d55",
      "src_ip": "187.100.149.54",
      "dst_ip": "33.29.174.118"
    },
      ...
    {
      "ticket_id": 9,
      "timestamp": "2015/12/10 17:28:48",
      "file_hash": "cafc9c5ec7ebc133",
      "src_ip": "210.205.230.140",
      "dst_ip": "99.31.12.3"
    }
  ]
}
```
    - solution
      - > Pipe it up, pipe it up, pipe it up, pipe it up  
      - > Pipe it up, pipe it up, pipe it up, pipe it up  
      - > - Migos, Pipe it up
      - => https://www.youtube.com/watch?v=8g2KKGgK-0w
      - In jq you just create an array of the number of unique destination IPs for each file hash, then calculate the average:
        - ```bash
$ cat incidents.json \
  | jq '[
          .tickets
          | group_by(.file_hash)[]
          | unique_by(.dst_ip)
          | length
        ]
        | add / length'
```

        - jq accepts a JSON document as input, so first we `cat` our JSON data into jq. In jq, arrays and individual elements can be piped into other functions.
    - ### group_by
      - The first step is pretty straight forward. We select `tickets` and group the objects the objects by their `.file_hash` attribute, giving us this:
      - ```bash
$ cat incidents.json \
  | jq '[
          .tickets
          | group_by(.file_hash)[]
        ]'
```

        - output:
          - ```JSON
[
  [
    {
      "ticket_id": 3,
      "timestamp": "2017/08/14 18:02:17",
      "file_hash": "1a03d0a86d991e91",
      "src_ip": "122.231.138.129",
      "dst_ip": "88.148.199.124"
    }
  ],
  [
    {
      "ticket_id": 5,
      "timestamp": "2015/08/17 20:48:14",
      "file_hash": "43e10d21eb3f5dc8",
      "src_ip": "210.205.230.140",
      "dst_ip": "50.225.199.154"
    },
    {
      "ticket_id": 7,
      "timestamp": "2015/03/18 22:37:20",
      "file_hash": "43e10d21eb3f5dc8",
      "src_ip": "122.231.138.129",
      "dst_ip": "209.104.88.119"
    }
  ],
  ...
  [
    {
      "ticket_id": 0,
      "timestamp": "2017/06/10 07:50:14",
      "file_hash": "fb0abe9b2a37e234",
      "src_ip": "131.90.8.180",
      "dst_ip": "104.97.128.21"
    },
    {
      "ticket_id": 8,
      "timestamp": "2015/07/08 17:11:17",
      "file_hash": "fb0abe9b2a37e234",
      "src_ip": "93.124.108.240",
      "dst_ip": "33.29.174.118"
    }
  ]
]
```
    - ### unique_by

      - Next we find the objects with unique destination ips within each of these groups. I'm not sure how jq decides which object to select from a group that share a value, but it doesn't matter for our purposes.
        - ```bash
      $ cat incidents.json \
        | jq '[
                .tickets
                | group_by(.file_hash)[]
                | unique_by(.dst_ip)
              ]'
      ```
      - output:
        - ```JSON
[
  [
    {
      "ticket_id": 3,
      "timestamp": "2017/08/14 18:02:17",
      "file_hash": "1a03d0a86d991e91",
      "src_ip": "122.231.138.129",
      "dst_ip": "88.148.199.124"
    }
  ],
  [
    {
      "ticket_id": 7,
      "timestamp": "2015/03/18 22:37:20",
      "file_hash": "43e10d21eb3f5dc8",
      "src_ip": "122.231.138.129",
      "dst_ip": "209.104.88.119"
    },
    {
      "ticket_id": 5,
      "timestamp": "2015/08/17 20:48:14",
      "file_hash": "43e10d21eb3f5dc8",
      "src_ip": "210.205.230.140",
      "dst_ip": "50.225.199.154"
    }
  ],
  ...
  [
    {
      "ticket_id": 0,
      "timestamp": "2017/06/10 07:50:14",
      "file_hash": "fb0abe9b2a37e234",
      "src_ip": "131.90.8.180",
      "dst_ip": "104.97.128.21"
    },
    {
      "ticket_id": 8,
      "timestamp": "2015/07/08 17:11:17",
      "file_hash": "fb0abe9b2a37e234",
      "src_ip": "93.124.108.240",
      "dst_ip": "33.29.174.118"
    }
  ]
]
```

    - ### length

      - Then we get the number of objects in each group

        - ```bash
$ cat incidents.json \
  | jq '[
          .tickets
          | group_by(.file_hash)[]
          | unique_by(.dst_ip)
          | length
        ]'
```
      - output:
        - ```JSON
[
  1,
  2,
  1,
  1,
  1,
  2,
  2
]
```

    - ### add / length

      - Then you can just pipe that array into `add / length` to calculate the average for the array

        - ```bash
$ cat incidents.json \
  | jq '[
          .tickets
          | group_by(.file_hash)[]
          | unique_by(.dst_ip)
          | length
        ]
        | add / length'
```
      - output:
        - ```JSON
1.4285714285714286
```


- sometimes I talk
  - server-sent events
    - A brief introduction to server-sent events, when to use them and when not to use them.
    - => /images/sse.png
    - => https://docs.google.com/presentation/d/1i2vT6nMrRUsmFusH8HL-0fHZUEifyniL_8q0f0pBCBg/edit?usp=sharing
  - schematron
    - Introduction to Schematron, a language for validating XML documents.
    - => /images/schematron.png
    - => https://docs.google.com/presentation/d/16wpjtIqwqj0yagdQcObRzdDI6l_gYxCX/edit?usp=sharing&ouid=111583935946353067252&rtpof=true&sd=true


- $ resume
  - education
    - M.S. in computer science
      - University of Chicago, 3.9 / 4.0, 2018-2019
      - Algorithms, C Programming, Operating Systems, Networks, Parallel Programming, Big Data, Application Security, Intro to Computer Systems, Discrete Math
    - B.S. double major neuroscience & chinese studies
      - Furman University, 3.48 / 4.0, 2012-2016
  - work experience
    - Replit, senior software engineer
      - February 2022 - September 2024
      - Bringing the the next billion software creators online.
    - Devetry, senior software engineer
      - February 2022 - September 2024
        - Solving complex problems for clients with custom software and codebase improvements (Python, Django, Golang, JavaScript, XML Schema, PHP)
        - Tech lead for the rebuilding of the Devetry website (Netlify, React)
    - University of Chicago - Globus Labs, graduate practicum student
      - January 2019 - June 2019
      - Created Python package which automates the process of deploying, running, and optimizing arbitrary programs
      - Used Bayesian Optimization to significantly reduce the amount of time required optimize tool configuration
      - Created RESTful web service for running jobs with the package on AWS and storing results using Flask, Redis, Docker Compose and PostgreSQL
    - University of Chicago - Center for Translational Data Science, software developer
      - May 2018 - May 2019
      - Used Node.js, Groovy, Bash, and Docker to develop tools and automation for Kubernetes management and CI/CD pipelines in Jenkins
      - Created custom canary rollout method using Kubernetes, JavaScript, and NGINX
    - NORC, graduate research assistant II, software developer
      - Refactored, enhanced, and fixed previous bugs in Django web application backend
      - Designed and created a custom survey frontend using vanilla JavaScript, primarily targeted at mobile use
      - Created tools and statistical analysis reports on data collected through the platform using Pandas
    - Furman University, lab coordinator
      - June 2016 - July 2017
      - Created data processing pipelines for organizing, cleaning, and merging eye tracking, EEG and behavioral data using Jupyter notebooks, Pandas, Numpy, and matplotlib
      - Created an embedded database application in Java with functional GUI for more effective recruitment
  - tools and such
    - watever


- contact me
  - => mailto:ted.summer2@gmail.com
  - => https://github.com/macintoshpie
  - => https://twitter.com/macint0shpie
  - => https://linkedin.com/in/tedsummer
